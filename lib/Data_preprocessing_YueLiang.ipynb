{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Data_preprocessing_YueLiang.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6_NHMkvjfHzt"
      },
      "source": [
        "# **Import Required Packages**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Sul9PJjDfFlb"
      },
      "source": [
        "import numpy as np\n",
        "import scipy.io\n",
        "import sklearn.metrics\n",
        "import sklearn \n",
        "import os\n",
        "import random\n",
        "import pandas as pd\n",
        "import time"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bsorsa-ab9Rk"
      },
      "source": [
        "# **Read the files**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CAMr80-b-5Xb",
        "outputId": "0403fff9-e4aa-4a9a-f403-3878f84c9420",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# When using Colab, you can upload train_set.zip in the content folder and run this kernel.\n",
        "!unzip -q /content/train_set.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gb42Hl_Wg2Lb"
      },
      "source": [
        "# Set your directory to read the data, default is the directory in colab.\n",
        "unzipped_folder_path = '/content/train_set'"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_J2UVY-rUVwY"
      },
      "source": [
        "def read_data(unzipped_folder_path):\n",
        "  \n",
        "  # read labels\n",
        "  labels = pd.read_csv(unzipped_folder_path+'/label.csv')\n",
        "  y= labels['label'].to_numpy()\n",
        "\n",
        "  # read points\n",
        "  n = 3000\n",
        "  for i in range(1,n+1):\n",
        "    p_path = str(i).zfill(4)+'.mat'\n",
        "    mat = scipy.io.loadmat(unzipped_folder_path+'/points/'+p_path)\n",
        "    if 'faceCoordinatesUnwarped' in mat:\n",
        "      cords = mat['faceCoordinatesUnwarped'] \n",
        "    else:\n",
        "      cords = mat['faceCoordinates2']\n",
        "\n",
        "    distance = sklearn.metrics.pairwise_distances(cords)       \n",
        "          # compute the pairwise distances in each mat\n",
        "    flatten_distance = distance[np.triu_indices(len(cords[:,0]), k = 1)]    \n",
        "          # stretch the upper triangle of the symmetric matrix \n",
        "          # to a long array with dimension 3003\n",
        "          # 3003 = (1+77)*78/2\n",
        "    if i==1:\n",
        "      distances = np.mat([flatten_distance])\n",
        "    else:\n",
        "      distances = np.append(distances, np.mat([flatten_distance]), axis = 0)\n",
        "  return (distances, y)\n"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j3sddESRgvbO",
        "outputId": "9868fb72-68d9-4a69-da69-b9a9cb7a96c0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "read_time_start=time.time()\n",
        "Ori_X, Ori_Y = read_data(unzipped_folder_path)\n",
        "print(\"Read the original dataset takes %s seconds\" % round((time.time() - read_time_start),3))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Read the original dataset takes 39.342 seconds\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjbBlHljls8Q",
        "outputId": "6fc8c6ae-5e7d-4022-fbc0-3c6a69cb5e6b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Ori_X.shape, Ori_Y.shape \n",
        "# should be (3000,3003) and (3000,) \n",
        "# which means 3000 number of cases \n",
        "# and 3003 numbers of pairwise distances\n",
        "# of 78 fiducial points. \n",
        "# 3003 = (1+77)*78/2"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((3000, 3003), (3000,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wUfrQ1rTjBHs"
      },
      "source": [
        "# **Data Preprocessing For the Imbalanced Dataset & Generate New Data to Improve Learning Accuracy** \n",
        "## From the following analysis, we found that the Original Dataset is unbalanced. So we decided to generate new data for the class with smaller number of original samples. By generating new data, we not only balanced the data with equal number of samples in different class, but also create new data to help improve the learning accuracy.\n",
        "\n",
        "* Because the number of Class 1 samples is less than the number of Class 0 samples, we decided to add more data in Class 1.\n",
        "* The way we generate more data is that we randomly select two original cordinates of fiducial points in Class 1 and average them to generate new data of fiducial points and then calculate its pairwise distances and give it the label of 1. \n",
        "* It would make sense cause our models believe that the fiducial points in the same class will generate similar distribution in pairwise distances."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ef2jCi9po8Kn",
        "outputId": "37c55469-bacd-4868-aa3c-627505fbf17d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# Analyzing the data\n",
        "n = Ori_Y.shape[0]\n",
        "print('The number of class 0 is ' + str(n-sum(Ori_Y)))\n",
        "print('The number of class 1 is ' + str(sum(Ori_Y)))\n",
        "print('Only %.2f'% (sum(Ori_Y)/n*100) + '% of total dataset are class 1. ')\n",
        "print('So, it is an unbalanced dataset, we need to do some data preprocessing.')\n",
        "print('Here, we are using oversampling to generate more class 1 datasets.')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "The number of class 0 is 2402\n",
            "The number of class 1 is 598\n",
            "Only 19.93% of total dataset are class 1. \n",
            "So, it is an unbalanced dataset, we need to do some data preprocessing.\n",
            "Here, we are using oversampling to generate more class 1 datasets.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XZU3iWqS_XoL"
      },
      "source": [
        "def data_preprocessing(Ori_X, Ori_Y, unzipped_folder_path):\n",
        "\n",
        "  # data preprocessing\n",
        "\n",
        "  distances = Ori_X\n",
        "  y = Ori_Y\n",
        "\n",
        "  n = y.shape[0]\n",
        "  mat_1 = np.add(np.where(y == 1),1)\n",
        "  n_oversample = (n-sum(y))-sum(y) \n",
        "    # how many samples do we need to generate\n",
        "\n",
        "  for i in range(n_oversample):\n",
        "    samples_index = random.sample(list(list(mat_1)[0]), 2)\n",
        "      # pick two random index of class 1 samples. \n",
        "\n",
        "    p_path = str(samples_index[0]).zfill(4)+'.mat'\n",
        "    mat = scipy.io.loadmat(unzipped_folder_path+'/points/'+p_path)\n",
        "    if 'faceCoordinatesUnwarped' in mat:\n",
        "      cords_0 = mat['faceCoordinatesUnwarped'] \n",
        "    else:\n",
        "      cords_0 = mat['faceCoordinates2']\n",
        "    \n",
        "    p_path = str(samples_index[1]).zfill(4)+'.mat'\n",
        "    mat = scipy.io.loadmat(unzipped_folder_path+'/points/'+p_path)\n",
        "    if 'faceCoordinatesUnwarped' in mat:\n",
        "      cords_1 = mat['faceCoordinatesUnwarped'] \n",
        "    else:\n",
        "      cords_1 = mat['faceCoordinates2']\n",
        "\n",
        "    cords_new = (cords_0 + cords_1) / 2 \n",
        "        # averaging two sets of cordinates to generate new set of cordinates\n",
        "    distance = sklearn.metrics.pairwise_distances(cords_new)\n",
        "        # compute the pairwise distances in each mat\n",
        "    flatten_distance = distance[np.triu_indices(len(cords_new[:,0]), k = 1)]\n",
        "        # stretch the upper triangle of the symmetric matrix \n",
        "        # to a long array with dimension 3003\n",
        "        # 3003 = (1+77)*78/2\n",
        "    \n",
        "    distances = np.append(distances, np.mat([flatten_distance]), axis = 0)\n",
        "    y = np.append(y,np.array(1))\n",
        "        # Append new data to the original dataset\n",
        "\n",
        "  return (distances, y) \n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YVZH9NK0xfIc"
      },
      "source": [
        "Balanced_X, Blanced_Y = data_preprocessing(Ori_X, Ori_Y, unzipped_folder_path)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EiKZwvM84VmY",
        "outputId": "1b82035a-78e8-433a-9cf3-a8d9705df483",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "Balanced_X.shape, Blanced_Y.shape"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((4804, 3003), (4804,))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    }
  ]
}